{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37855d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "import sys \n",
    "sys.path.insert(1, os.path.dirname(os.getcwd()))\n",
    "from functions import *\n",
    "import numpy as np \n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb6930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "train_size, val_size = 80, 40\n",
    "look_back, look_fwd = 10, 10\n",
    "batch_size = 8\n",
    "nodes, kernel_size = 128, 1\n",
    "activation = 'tanh'\n",
    "\n",
    "autoencoder = tf.keras.saving.load_model('cae.keras') \n",
    "\n",
    "# Physical constants\n",
    "const_dict = load_constants()\n",
    "Uf, P, T_h, T_0, Pr, Ra = get_model_constants(const_dict)\n",
    "\n",
    "############################################\n",
    "\n",
    "# CREATE SEQUENCE GENERATOR. SAVED WEIGHTS WILL BE LOADED\n",
    "@register_keras_serializable()\n",
    "class SequenceGenerator(tf.keras.Model):\n",
    "  def __init__(self, hidden_size, kernel_size, out_size):\n",
    "    super(SequenceGenerator, self).__init__(name='SequenceGenerator_Model')\n",
    "    self.hidden_size = hidden_size\n",
    "    self.kernel_size = kernel_size\n",
    "    self.out_size = out_size\n",
    "    self.rnn = ConvLSTM2D(hidden_size, kernel_size, return_state=True, padding='same', name='ConvLSTM_SG')\n",
    "    self.conv = Conv2D(64, kernel_size=3, padding='same', name='Conv2D') \n",
    "    self.norm = LayerNormalization(name='Norm')\n",
    "    self.act = LeakyReLU(0.2, name='ReLU')\n",
    "    self.expand_dim = Lambda(lambda x: tf.expand_dims(x, axis=1))\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    initial_input_shape = input_shape[0]\n",
    "    h_shape = c_shape = (1, 16, 16, self.hidden_size)\n",
    "\n",
    "    dummy_input = tf.zeros(initial_input_shape)\n",
    "    dummy_h = tf.zeros(h_shape)\n",
    "    dummy_c = tf.zeros(c_shape)\n",
    "\n",
    "    dec_o, _, _ = self.rnn(dummy_input, initial_state=[dummy_h, dummy_c])\n",
    "    _ = self.act(self.norm(self.conv(dec_o)))\n",
    "    super().build(input_shape)\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    initial_input, h, c, targets, autoreg_prob = inputs\n",
    "    T = tf.shape(targets)[1]\n",
    "    t_switch = tf.cast(T, tf.float32) * autoreg_prob\n",
    "    outputs = tf.TensorArray(dtype=tf.float32, size=T)\n",
    "    input_at_t = initial_input\n",
    "      \n",
    "    def cond_autoreg(t, input_at_t, h, c, outputs):\n",
    "      return tf.cast(t, tf.float32) < t_switch\n",
    "      \n",
    "    def body_autoreg(t, input_at_t, h, c, outputs):\n",
    "      dec_o, h, c = self.rnn(input_at_t, initial_state=[h, c])\n",
    "      output = self.act(self.norm(self.conv(dec_o)))\n",
    "      outputs = outputs.write(t, output)\n",
    "      input_at_t = self.expand_dim(output)\n",
    "      return t + 1, input_at_t, h, c, outputs\n",
    "      \n",
    "    def cond_teacher(t, input_at_t, h, c, outputs):\n",
    "      return tf.cast(t, tf.float32) < tf.cast(T, tf.float32)\n",
    "\n",
    "    def body_teacher(t, input_at_t, h, c, outputs):\n",
    "      dec_o, h, c = self.rnn(input_at_t, initial_state=[h, c])\n",
    "      output = self.act(self.norm(self.conv(dec_o)))\n",
    "      outputs = outputs.write(t, output)\n",
    "      input_at_t = targets[:, t:t+1]\n",
    "      return t + 1, input_at_t, h, c, outputs\n",
    "\n",
    "    t = tf.constant(0)\n",
    "    shape_invs = [t.get_shape(), tf.TensorShape([None, None, 16, 16, self.out_size]), tf.TensorShape([None, 16, 16, 128]), tf.TensorShape([None, 16, 16, 128]), tf.TensorShape(None)]\n",
    "    t, input_at_t, h, c, outputs = tf.while_loop(cond_autoreg, body_autoreg, loop_vars=[t, input_at_t, h, c, outputs], shape_invariants=shape_invs)\n",
    "    t, input_at_t, h, c, outputs = tf.while_loop(cond_teacher, body_teacher, loop_vars=[t, input_at_t, h, c, outputs], shape_invariants=shape_invs)\n",
    "    return tf.transpose(outputs.stack(), perm=[1,0,2,3,4])  \n",
    "\n",
    "  def get_config(self):    \n",
    "    config = super().get_config()\n",
    "    config.update({\"hidden_size\": self.hidden_size, \"kernel_size\": self.kernel_size, 'out_size':self.out_size})\n",
    "    return config\n",
    "    \n",
    "  @classmethod\n",
    "  def from_config(cls, config):\n",
    "    return cls(**config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee67c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the 4 pieces of the spatiotemporal model and data\n",
    "ae_encoder = build_ae_encoder(autoencoder)\n",
    "context_builder = tf.keras.saving.load_model('context_builder.keras')\n",
    "sequence_generator = SequenceGenerator(hidden_size=nodes, kernel_size=kernel_size, out_size=64)\n",
    "sequence_generator.load_weights('sequence_generator.weights.h5', overwrite=True)\n",
    "ae_decoder = build_ae_decoder(autoencoder)\n",
    "\n",
    "data_train, data_val, x, z, _ = load_data(2000, 500, Uf, P, T_h, T_0)\n",
    "uwpT = np.concatenate((data_train, data_val), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113441ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to forecast given an input sequence\n",
    "def run_forecast(input_rbc, horizon):\n",
    "    input_encoder = ae_encoder.predict(tf.expand_dims(input_rbc, axis=0), verbose=0)\n",
    "    h, c = context_builder(input_encoder, training=False)\n",
    "    x = sequence_generator(input_encoder[:,-1:], h, c, horizon, training=False)\n",
    "    forecast = ae_decoder.predict(x, verbose=0, batch_size=8) \n",
    "    return forecast[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2be6d29",
   "metadata": {},
   "source": [
    "## Forecast / Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7c7793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "formatter = FuncFormatter(lambda x, pos: f'{x:.1e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0815fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 20\n",
    "\n",
    "forecast = run_forecast(data_val[:look_back], horizon)\n",
    "\n",
    "mins_data = uwpT.min(axis=(0,1,2)).reshape(1,-1)\n",
    "maxs_data = uwpT.max(axis=(0,1,2)).reshape(1,-1)\n",
    "mins_f = forecast.min(axis=(0,1,2)).reshape(1,-1)\n",
    "maxs_f = forecast.max(axis=(0,1,2)).reshape(1,-1)\n",
    "\n",
    "mins = np.concatenate((mins_data, mins_f), axis=0).min(axis=0)\n",
    "maxs = np.concatenate((maxs_data, maxs_f), axis=0).max(axis=0)\n",
    "\n",
    "X, Z = np.meshgrid(x, z)\n",
    "\n",
    " \n",
    "t_ = np.arange(1, forecast.shape[0]+1) * 0.05\n",
    "t_list = np.linspace(0, horizon-1, 5).astype('int')\n",
    "\n",
    "fig, ax = plt.subplots(2, len(t_list), figsize=(20,7), layout='constrained')\n",
    "\n",
    "for j, t in enumerate(t_list):        \n",
    "    im1 = ax[0,j%5].contourf(X, Z, forecast[t,...,3].T, cmap='jet', vmin=mins[-1], vmax=maxs[-1], levels=np.linspace(mins[-1],maxs[-1],40))\n",
    "    im1 = ax[1,j%5].contourf(X, Z, data_val[t,...,3].T, cmap='jet', vmin=mins[-1], vmax=maxs[-1], levels=np.linspace(mins[-1],maxs[-1],40))\n",
    "\n",
    "ax[0,j%5].set_title(r'$t$ =' + f' {t_[t]:.2f}s', fontsize=15)\n",
    "\n",
    "cbar1 = plt.colorbar(im1, ax=ax[1,:], orientation='horizontal', shrink=0.4, aspect=20, pad=0.05)\n",
    "cbar1.locator = ticker.MaxNLocator(nbins=5)\n",
    "cbar1.update_ticks()\n",
    "\n",
    "for i in range(5): ax[0,i].xaxis.set_visible(False)\n",
    "ax[0,1].yaxis.set_visible(False)\n",
    "ax[0,2].yaxis.set_visible(False)\n",
    "ax[0,3].yaxis.set_visible(False)\n",
    "ax[0,4].yaxis.tick_right() \n",
    "ax[0,4].yaxis.set_ticks_position('right')\n",
    "\n",
    "ax[1,1].yaxis.set_visible(False)\n",
    "ax[1,2].yaxis.set_visible(False)\n",
    "ax[1,3].yaxis.set_visible(False)\n",
    "ax[1,4].yaxis.tick_right() \n",
    "ax[1,4].yaxis.set_ticks_position('right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab9046",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f9f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first generate an ensemble of forecast, all of the same length\n",
    "# with input sequences taken from the validation set\n",
    "\n",
    "ensembles = 30\n",
    "horizon = 20\n",
    "\n",
    "forecast_starts = np.linspace(look_back, val_size-1, ensembles).astype('int')\n",
    "\n",
    "forecast_ensemble = []\n",
    "for s in forecast_starts:\n",
    "    input_rbc_temp = data_val[(s-look_back):s]\n",
    "    forecast_temp = run_forecast(input_rbc_temp, horizon)\n",
    "    forecast_ensemble.append(forecast_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82683eac",
   "metadata": {},
   "source": [
    "### PDE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7309ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx, dz, dt = get_grads(x, z, const_dict, Uf)\n",
    "\n",
    "pde_losses = []\n",
    "for i in range(ensembles):\n",
    "    forecast_temp = forecast_ensemble[i]\n",
    "    pde_residuals_temp = ns_loss(forecast_temp, Pr, Ra, dx, dz, dt) # shape (horizon, 256, 256, 4)\n",
    "    pde_loss_temp = (pde_residuals_temp**2).mean()\n",
    "    pde_losses.append(pde_loss_temp)\n",
    "\n",
    "print(f'PDE Loss: {np.median(pde_losses):.2e} ({np.quantile(pde_losses, 0.75) - np.quantile(pde_losses, 0.25):.2e})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e2169",
   "metadata": {},
   "source": [
    "### Nusselt Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7bf251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true Nu number\n",
    "j_conv = uwpT[...,127,1:2] * (uwpT[...,127,-1:] - tf.reduce_mean(uwpT[...,127,-1:], axis=(0,1,2), keepdims=True) ) \n",
    "Nu_true = 1 + tf.math.sqrt(Pr*Ra) * tf.reduce_mean(j_conv)\n",
    "\n",
    "# predicted\n",
    "Nus = []\n",
    "for i in range(ensembles):\n",
    "    forecast_temp = forecast_ensemble[i]\n",
    "    j_conv = forecast_temp[...,127,1:2] * (forecast_temp[...,127,-1:] - tf.reduce_mean(forecast_temp[...,127,-1:], axis=(0,1,2), keepdims=True) ) \n",
    "    Nus.append(1 + tf.math.sqrt(Pr*Ra) * tf.reduce_mean(j_conv))\n",
    "\n",
    "print(f'Nu true: {Nu_true:.2f}. Pred: {np.median(Nus):.4f} ({np.quantile(Nus, 0.75) - np.quantile(Nus, 0.25):.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c7d4b2",
   "metadata": {},
   "source": [
    "### PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c745cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3dc9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = ['u','w','p','T']\n",
    "x_grid_size = 500\n",
    "\n",
    "kls = {}\n",
    "for i, v in enumerate(['u','w','T']):\n",
    "    j = var_list.index(v)\n",
    "    forecast_ensemble_var = forecast_ensemble[...,j]\n",
    "    x_range = np.linspace(uwpT[...,j].min(), uwpT[...,j].max(), x_grid_size)\n",
    "\n",
    "    kde_true = []\n",
    "    for s in np.linspace(0, uwpT.shape[0]-horizon-1, ensembles):\n",
    "      kde_true.append( gaussian_kde(uwpT[int(s):int(s+horizon),...,j].flatten())(x_range) )\n",
    "    kde_true = np.asarray(kde_true)\n",
    "    pdf_true = np.clip(np.asarray(kde_true).mean(axis=0), 1e-10, None)\n",
    "\n",
    "    kl_temp = []\n",
    "    for k in range(ensembles):\n",
    "        kde_temp = gaussian_kde(forecast_ensemble_var[k].flatten())\n",
    "        pdf_temp = np.clip(kde_temp(x_range), 1e-10, None)\n",
    "        kl_temp.append( (pdf_true * np.log(pdf_true / pdf_temp)).sum() ) \n",
    "\n",
    "    print(f'{v}. Median: {np.median(kl_temp):.2e}, iqr: {np.quantile(kl_temp, 0.75) - np.quantile(kl_temp, 0.25):.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c5f07f",
   "metadata": {},
   "source": [
    "### Dissipation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25303b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true dissipation\n",
    "\n",
    "z_beg = 25\n",
    "z_end = 230 \n",
    "epsilon_T = np.array( DX(uwpT[...,-1:], dx)**2 + DZ(uwpT[...,-1:], dz)**2 )[...,z_beg:z_end,-1].mean(axis=0)\n",
    "epsilon_T = epsilon_T * const_dict['kappa'][0,0] * (const_dict['T_bot'][0,0]-const_dict['T_top'][0,0])**2\n",
    "\n",
    "epsilon_T_pred = []\n",
    "for i in range(ensembles):\n",
    "    epsilon_T_temp = np.array( DX(forecast_ensemble[i,...,-1:], dx)**2 + DZ(forecast_ensemble[i,...,-1:], dz[z_beg:z_end])**2 ).mean(axis=0)\n",
    "    epsilon_T_pred.append(epsilon_T_temp * const_dict['kappa'][0,0] * (const_dict['T_bot'][0,0]-const_dict['T_top'][0,0])**2 )\n",
    "\n",
    "diff = np.asarray(epsilon_T_pred)[...,0] - np.expand_dims(epsilon_T, axis=0)\n",
    "error = diff**2 \n",
    "med = np.median(error.mean(axis=(1,2)))\n",
    "q1 = np.quantile(error.mean(axis=(1,2)), 0.25)\n",
    "q2 = np.quantile(error.mean(axis=(1,2)), 0.75)\n",
    "\n",
    "print(f'Dissipation error: {med:.2e} ({q2-q1:.2e})')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
